{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKPK-_pj-BE3"
   },
   "source": [
    "# Simple RAG (Retrieval-Augmented Generation) System\n",
    "\n",
    "## Overview\n",
    "\n",
    "This code implements a basic Retrieval-Augmented Generation (RAG) system for processing and querying PDF documents. The system encodes the document content into a vector store, which can then be queried to retrieve relevant information.\n",
    "\n",
    "## Key Components\n",
    "\n",
    "1. PDF processing and text extraction\n",
    "2. Text chunking for manageable processing\n",
    "3. Vector store creation using [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/) and OpenAI embeddings\n",
    "4. Retriever setup for querying the processed documents\n",
    "5. Evaluation of the RAG system\n",
    "\n",
    "## Method Details\n",
    "\n",
    "### Document Preprocessing\n",
    "\n",
    "1. The PDF is loaded using PyPDFLoader.\n",
    "2. The text is split into chunks using RecursiveCharacterTextSplitter with specified chunk size and overlap.\n",
    "\n",
    "### Text Cleaning\n",
    "\n",
    "A custom function `replace_t_with_space` is applied to clean the text chunks. This likely addresses specific formatting issues in the PDF.\n",
    "\n",
    "### Vector Store Creation\n",
    "\n",
    "1. OpenAI embeddings are used to create vector representations of the text chunks.\n",
    "2. A FAISS vector store is created from these embeddings for efficient similarity search.\n",
    "\n",
    "### Retriever Setup\n",
    "\n",
    "1. A retriever is configured to fetch the top 2 most relevant chunks for a given query.\n",
    "\n",
    "### Encoding Function\n",
    "\n",
    "The `encode_pdf` function encapsulates the entire process of loading, chunking, cleaning, and encoding the PDF into a vector store.\n",
    "\n",
    "## Key Features\n",
    "\n",
    "1. Modular Design: The encoding process is encapsulated in a single function for easy reuse.\n",
    "2. Configurable Chunking: Allows adjustment of chunk size and overlap.\n",
    "3. Efficient Retrieval: Uses FAISS for fast similarity search.\n",
    "4. Evaluation: Includes a function to evaluate the RAG system's performance.\n",
    "\n",
    "## Usage Example\n",
    "\n",
    "The code includes a test query: \"What is the main cause of climate change?\". This demonstrates how to use the retriever to fetch relevant context from the processed document.\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "The system includes an `evaluate_rag` function to assess the performance of the retriever, though the specific metrics used are not detailed in the provided code.\n",
    "\n",
    "## Benefits of this Approach\n",
    "\n",
    "1. Scalability: Can handle large documents by processing them in chunks.\n",
    "2. Flexibility: Easy to adjust parameters like chunk size and number of retrieved results.\n",
    "3. Efficiency: Utilizes FAISS for fast similarity search in high-dimensional spaces.\n",
    "4. Integration with Advanced NLP: Uses OpenAI embeddings for state-of-the-art text representation.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This simple RAG system provides a solid foundation for building more complex information retrieval and question-answering systems. By encoding document content into a searchable vector store, it enables efficient retrieval of relevant information in response to queries. This approach is particularly useful for applications requiring quick access to specific information within large documents or document collections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvUHveE5-BE3"
   },
   "source": [
    "# Package Installation and Imports\n",
    "\n",
    "The cell below installs all necessary packages required to run this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVaHWFwh-BE4",
    "outputId": "d725de55-3b6e-45ad-a599-ca0f4e7d1698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf==5.6.0\n",
      "  Downloading pypdf-5.6.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in c:\\python310\\lib\\site-packages (from pypdf==5.6.0) (4.15.0)\n",
      "Downloading pypdf-5.6.0-py3-none-any.whl (304 kB)\n",
      "Installing collected packages: pypdf\n",
      "  Attempting uninstall: pypdf\n",
      "    Found existing installation: pypdf 6.1.3\n",
      "    Uninstalling pypdf-6.1.3:\n",
      "      Successfully uninstalled pypdf-6.1.3\n",
      "Successfully installed pypdf-5.6.0\n",
      "Collecting PyMuPDF==1.26.1\n",
      "  Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Downloading pymupdf-1.26.1-cp39-abi3-win_amd64.whl (18.5 MB)\n",
      "   ---------------------------------------- 0.0/18.5 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.1/18.5 MB 16.8 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 4.2/18.5 MB 12.6 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 6.3/18.5 MB 11.4 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 8.4/18.5 MB 11.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 10.5/18.5 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 12.6/18.5 MB 11.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 14.7/18.5 MB 11.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 16.8/18.5 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.5/18.5 MB 10.9 MB/s  0:00:01\n",
      "Installing collected packages: PyMuPDF\n",
      "Successfully installed PyMuPDF-1.26.1\n",
      "Collecting python-dotenv==1.1.0\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "  Attempting uninstall: python-dotenv\n",
      "    Found existing installation: python-dotenv 1.1.1\n",
      "    Uninstalling python-dotenv-1.1.1:\n",
      "      Successfully uninstalled python-dotenv-1.1.1\n",
      "Successfully installed python-dotenv-1.1.0\n",
      "Collecting langchain-community==0.3.25\n",
      "  Downloading langchain_community-0.3.25-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.65 (from langchain-community==0.3.25)\n",
      "  Downloading langchain_core-0.3.79-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.25 (from langchain-community==0.3.25)\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\python310\\lib\\site-packages (from langchain-community==0.3.25) (2.0.44)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python310\\lib\\site-packages (from langchain-community==0.3.25) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\python310\\lib\\site-packages (from langchain-community==0.3.25) (6.0.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\python310\\lib\\site-packages (from langchain-community==0.3.25) (3.13.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\python310\\lib\\site-packages (from langchain-community==0.3.25) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\python310\\lib\\site-packages (from langchain-community==0.3.25) (0.6.7)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.25)\n",
      "  Downloading pydantic_settings-2.11.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community==0.3.25)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.25)\n",
      "  Downloading httpx_sse-0.4.3-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\python310\\lib\\site-packages (from langchain-community==0.3.25) (2.2.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\python310\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25) (1.22.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.25) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\python310\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.25) (0.9.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain<1.0.0,>=0.3.25->langchain-community==0.3.25)\n",
      "  Downloading langchain_text_splitters-0.3.11-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\python310\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (2.12.3)\n",
      "Collecting async-timeout<6.0,>=4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.25)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (1.33)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python310\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.65->langchain-community==0.3.25) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (3.11.4)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\python310\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (1.0.0)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-community==0.3.25)\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: anyio in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community==0.3.25) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\python310\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.25) (1.1.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.25) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2->langchain-community==0.3.25) (2.3.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\python310\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.25) (3.2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\python310\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.25) (1.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community==0.3.25) (1.3.1)\n",
      "Downloading langchain_community-0.3.25-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 16.2 MB/s  0:00:00\n",
      "Downloading httpx_sse-0.4.3-py3-none-any.whl (9.0 kB)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 50.4 MB/s  0:00:00\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.79-py3-none-any.whl (449 kB)\n",
      "Downloading langchain_text_splitters-0.3.11-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Downloading pydantic_settings-2.11.0-py3-none-any.whl (48 kB)\n",
      "Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Installing collected packages: zstandard, httpx-sse, async-timeout, pydantic-settings, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "\n",
      "  Attempting uninstall: zstandard\n",
      "\n",
      "    Found existing installation: zstandard 0.25.0\n",
      "\n",
      "    Uninstalling zstandard-0.25.0:\n",
      "\n",
      "      Successfully uninstalled zstandard-0.25.0\n",
      "\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "  Attempting uninstall: async-timeout\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "   ---------------------------------------- 0/9 [zstandard]\n",
      "   -------- ------------------------------- 2/9 [async-timeout]\n",
      "  Attempting uninstall: langsmith\n",
      "   -------- ------------------------------- 2/9 [async-timeout]\n",
      "    Found existing installation: langsmith 0.4.38\n",
      "   -------- ------------------------------- 2/9 [async-timeout]\n",
      "    Uninstalling langsmith-0.4.38:\n",
      "   -------- ------------------------------- 2/9 [async-timeout]\n",
      "      Successfully uninstalled langsmith-0.4.38\n",
      "   -------- ------------------------------- 2/9 [async-timeout]\n",
      "   ----------------- ---------------------- 4/9 [langsmith]\n",
      "  Attempting uninstall: langchain-core\n",
      "   ----------------- ---------------------- 4/9 [langsmith]\n",
      "    Found existing installation: langchain-core 1.0.1\n",
      "   ----------------- ---------------------- 4/9 [langsmith]\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "    Uninstalling langchain-core-1.0.1:\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "      Successfully uninstalled langchain-core-1.0.1\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "  Attempting uninstall: langchain\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "    Found existing installation: langchain 1.0.2\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "    Uninstalling langchain-1.0.2:\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "      Successfully uninstalled langchain-1.0.2\n",
      "   ---------------------- ----------------- 5/9 [langchain-core]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ------------------------------- -------- 7/9 [langchain]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ----------------------------------- ---- 8/9 [langchain-community]\n",
      "   ---------------------------------------- 9/9 [langchain-community]\n",
      "\n",
      "Successfully installed async-timeout-4.0.3 httpx-sse-0.4.3 langchain-0.3.27 langchain-community-0.3.25 langchain-core-0.3.79 langchain-text-splitters-0.3.11 langsmith-0.3.45 pydantic-settings-2.11.0 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Python310\\Lib\\site-packages\\~standard'.\n",
      "  You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_openai==0.3.23\n",
      "  Downloading langchain_openai-0.3.23-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.65 in c:\\python310\\lib\\site-packages (from langchain_openai==0.3.23) (0.3.79)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\python310\\lib\\site-packages (from langchain_openai==0.3.23) (1.109.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\python310\\lib\\site-packages (from langchain_openai==0.3.23) (0.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (0.3.45)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (1.33)\n",
      "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (6.0.3)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (4.15.0)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\python310\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (2.12.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\python310\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (3.11.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (2.32.5)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\python310\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (4.11.0)\n",
      "Requirement already satisfied: certifi in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\python310\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\python310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai==0.3.23) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\python310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai==0.3.23) (0.11.1)\n",
      "Requirement already satisfied: sniffio in c:\\python310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai==0.3.23) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\python310\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai==0.3.23) (4.67.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\python310\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (0.4.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3,>=2->langsmith<1.0.0,>=0.3.45->langchain-core<1.0.0,>=0.3.65->langchain_openai==0.3.23) (2.3.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\python310\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai==0.3.23) (2025.10.23)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai==0.3.23) (0.4.6)\n",
      "Downloading langchain_openai-0.3.23-py3-none-any.whl (65 kB)\n",
      "Installing collected packages: langchain_openai\n",
      "Successfully installed langchain_openai-0.3.23\n",
      "Collecting rank_bm25==0.2.2\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: numpy in c:\\python310\\lib\\site-packages (from rank_bm25==0.2.2) (2.2.6)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: rank_bm25\n",
      "Successfully installed rank_bm25-0.2.2\n",
      "Collecting faiss-cpu==1.11.0\n",
      "  Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\python310\\lib\\site-packages (from faiss-cpu==1.11.0) (2.2.6)\n",
      "Requirement already satisfied: packaging in c:\\python310\\lib\\site-packages (from faiss-cpu==1.11.0) (25.0)\n",
      "Downloading faiss_cpu-1.11.0-cp310-cp310-win_amd64.whl (15.0 MB)\n",
      "   ---------------------------------------- 0.0/15.0 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 2.1/15.0 MB 14.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 4.2/15.0 MB 13.2 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.3/15.0 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 8.4/15.0 MB 11.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 10.5/15.0 MB 11.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.6/15.0 MB 11.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.0/15.0 MB 10.8 MB/s  0:00:01\n",
      "Installing collected packages: faiss-cpu\n",
      "  Attempting uninstall: faiss-cpu\n",
      "    Found existing installation: faiss-cpu 1.12.0\n",
      "    Uninstalling faiss-cpu-1.12.0:\n",
      "      Successfully uninstalled faiss-cpu-1.12.0\n",
      "Successfully installed faiss-cpu-1.11.0\n",
      "Collecting deepeval==3.1.0\n",
      "  Downloading deepeval-3.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: aiohttp in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (3.13.1)\n",
      "Requirement already satisfied: anthropic in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (0.71.0)\n",
      "Requirement already satisfied: click<8.2.0,>=8.0.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (8.1.6)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.9.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.46.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.67.1 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.76.0)\n",
      "Requirement already satisfied: nest_asyncio in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.6.0)\n",
      "Requirement already satisfied: ollama in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (0.6.0)\n",
      "Requirement already satisfied: openai in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.109.1)\n",
      "Requirement already satisfied: opentelemetry-api<2.0.0,>=1.24.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<2.0.0,>=1.24.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.38.0)\n",
      "Requirement already satisfied: portalocker in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (3.2.0)\n",
      "Requirement already satisfied: posthog<4.0.0,>=3.23.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (3.25.0)\n",
      "Requirement already satisfied: pyfiglet in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.0.4)\n",
      "Requirement already satisfied: pytest in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (8.4.2)\n",
      "Requirement already satisfied: pytest-asyncio in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (1.2.0)\n",
      "Requirement already satisfied: pytest-repeat in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (0.9.4)\n",
      "Requirement already satisfied: pytest-rerunfailures<13.0,>=12.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (12.0)\n",
      "Requirement already satisfied: pytest-xdist in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (3.8.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (2.32.5)\n",
      "Collecting rich<14.0.0,>=13.6.0 (from deepeval==3.1.0)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: sentry-sdk in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (2.42.1)\n",
      "Requirement already satisfied: setuptools in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (80.9.0)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (0.9.0)\n",
      "Collecting tenacity<=9.0.0 (from deepeval==3.1.0)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (4.67.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.9 in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (0.20.0)\n",
      "Requirement already satisfied: wheel in c:\\python310\\lib\\site-packages (from deepeval==3.1.0) (0.45.1)\n",
      "Requirement already satisfied: colorama in c:\\python310\\lib\\site-packages (from click<8.2.0,>=8.0.0->deepeval==3.1.0) (0.4.6)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in c:\\python310\\lib\\site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (4.11.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in c:\\python310\\lib\\site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (2.41.1)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in c:\\python310\\lib\\site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in c:\\python310\\lib\\site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (2.12.3)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\python310\\lib\\site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (15.0.1)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\python310\\lib\\site-packages (from google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (4.15.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (3.11)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\python310\\lib\\site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (1.3.1)\n",
      "Requirement already satisfied: cachetools<7.0,>=2.0.0 in c:\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (6.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\python310\\lib\\site-packages (from google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (4.9.1)\n",
      "Requirement already satisfied: certifi in c:\\python310\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\python310\\lib\\site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (0.16.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\python310\\lib\\site-packages (from opentelemetry-api<2.0.0,>=1.24.0->deepeval==3.1.0) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\python310\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.24.0->deepeval==3.1.0) (3.23.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.57 in c:\\python310\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.1.0) (1.71.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.38.0 in c:\\python310\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.1.0) (1.38.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.38.0 in c:\\python310\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.1.0) (1.38.0)\n",
      "Requirement already satisfied: protobuf<7.0,>=5.0 in c:\\python310\\lib\\site-packages (from opentelemetry-proto==1.38.0->opentelemetry-exporter-otlp-proto-grpc<2.0.0,>=1.24.0->deepeval==3.1.0) (6.33.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.59b0 in c:\\python310\\lib\\site-packages (from opentelemetry-sdk<2.0.0,>=1.24.0->deepeval==3.1.0) (0.59b0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python310\\lib\\site-packages (from posthog<4.0.0,>=3.23.0->deepeval==3.1.0) (1.17.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\python310\\lib\\site-packages (from posthog<4.0.0,>=3.23.0->deepeval==3.1.0) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\python310\\lib\\site-packages (from posthog<4.0.0,>=3.23.0->deepeval==3.1.0) (2.2.1)\n",
      "Requirement already satisfied: python-dateutil>2.1 in c:\\python310\\lib\\site-packages (from posthog<4.0.0,>=3.23.0->deepeval==3.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\python310\\lib\\site-packages (from posthog<4.0.0,>=3.23.0->deepeval==3.1.0) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\python310\\lib\\site-packages (from pydantic<3.0.0,>=2.0.0->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (0.4.2)\n",
      "Requirement already satisfied: packaging>=17.1 in c:\\python310\\lib\\site-packages (from pytest-rerunfailures<13.0,>=12.0->deepeval==3.1.0) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\python310\\lib\\site-packages (from requests<3.0.0,>=2.31.0->deepeval==3.1.0) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python310\\lib\\site-packages (from requests<3.0.0,>=2.31.0->deepeval==3.1.0) (2.3.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\python310\\lib\\site-packages (from rich<14.0.0,>=13.6.0->deepeval==3.1.0) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\python310\\lib\\site-packages (from rich<14.0.0,>=13.6.0->deepeval==3.1.0) (2.19.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\python310\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai<2.0.0,>=1.9.0->deepeval==3.1.0) (0.6.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\python310\\lib\\site-packages (from typer<1.0.0,>=0.9->deepeval==3.1.0) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.6.0->deepeval==3.1.0) (0.1.2)\n",
      "Requirement already satisfied: iniconfig>=1 in c:\\python310\\lib\\site-packages (from pytest->deepeval==3.1.0) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\python310\\lib\\site-packages (from pytest->deepeval==3.1.0) (1.6.0)\n",
      "Requirement already satisfied: tomli>=1 in c:\\python310\\lib\\site-packages (from pytest->deepeval==3.1.0) (2.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\python310\\lib\\site-packages (from aiohttp->deepeval==3.1.0) (1.22.0)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.15 in c:\\python310\\lib\\site-packages (from anthropic->deepeval==3.1.0) (0.17.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\python310\\lib\\site-packages (from anthropic->deepeval==3.1.0) (0.11.1)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\python310\\lib\\site-packages (from portalocker->deepeval==3.1.0) (311)\n",
      "Requirement already satisfied: backports-asyncio-runner<2,>=1.1 in c:\\python310\\lib\\site-packages (from pytest-asyncio->deepeval==3.1.0) (1.2.0)\n",
      "Requirement already satisfied: execnet>=2.1 in c:\\python310\\lib\\site-packages (from pytest-xdist->deepeval==3.1.0) (2.1.1)\n",
      "Downloading deepeval-3.1.0-py3-none-any.whl (547 kB)\n",
      "   ---------------------------------------- 0.0/548.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 548.0/548.0 kB 8.9 MB/s  0:00:00\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, rich, deepeval\n",
      "\n",
      "  Attempting uninstall: tenacity\n",
      "\n",
      "    Found existing installation: tenacity 9.1.2\n",
      "\n",
      "    Uninstalling tenacity-9.1.2:\n",
      "\n",
      "      Successfully uninstalled tenacity-9.1.2\n",
      "\n",
      "  Attempting uninstall: rich\n",
      "\n",
      "    Found existing installation: rich 14.2.0\n",
      "\n",
      "    Uninstalling rich-14.2.0:\n",
      "\n",
      "      Successfully uninstalled rich-14.2.0\n",
      "\n",
      "   ------------- -------------------------- 1/3 [rich]\n",
      "  Attempting uninstall: deepeval\n",
      "   ------------- -------------------------- 1/3 [rich]\n",
      "    Found existing installation: deepeval 3.3.9\n",
      "   ------------- -------------------------- 1/3 [rich]\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "    Uninstalling deepeval-3.3.9:\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "      Successfully uninstalled deepeval-3.3.9\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "   -------------------------- ------------- 2/3 [deepeval]\n",
      "   ---------------------------------------- 3/3 [deepeval]\n",
      "\n",
      "Successfully installed deepeval-3.1.0 rich-13.9.4 tenacity-9.0.0\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pypdf==5.6.0\n",
    "!pip install PyMuPDF==1.26.1\n",
    "!pip install python-dotenv==1.1.0\n",
    "!pip install langchain-community==0.3.25\n",
    "!pip install langchain_openai==0.3.23\n",
    "!pip install rank_bm25==0.2.2\n",
    "!pip install faiss-cpu==1.11.0\n",
    "!pip install deepeval==3.1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GGVwzS4v-BE5",
    "outputId": "e5a4d759-3a78-4b76-9670-0375c78757be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'RAG_TECHNIQUES'...\n",
      "remote: Enumerating objects: 1531, done.\u001b[K\n",
      "remote: Counting objects: 100% (808/808), done.\u001b[K\n",
      "remote: Compressing objects: 100% (359/359), done.\u001b[K\n",
      "remote: Total 1531 (delta 549), reused 458 (delta 449), pack-reused 723 (from 2)\u001b[K\n",
      "Receiving objects: 100% (1531/1531), 34.20 MiB | 25.58 MiB/s, done.\n",
      "Resolving deltas: 100% (962/962), done.\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository to access helper functions and evaluation modules\n",
    "!git clone https://github.com/NirDiamant/RAG_TECHNIQUES.git\n",
    "import sys\n",
    "sys.path.append('RAG_TECHNIQUES')\n",
    "\n",
    "# If you need to run with the latest data\n",
    "# !cp -r RAG_TECHNIQUES/data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ha6ASRqq-BE5",
    "outputId": "04acf50b-926e-4ff8-a5a3-6ecf11f74dd2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-622825101>:26: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from helper_functions import (EmbeddingProvider,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from google.colab import userdata\n",
    "\n",
    "\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable (comment out if not using OpenAI)\n",
    "if not userdata.get('OPENAI_API_KEY'):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = input(\"Please enter your OpenAI API key: \")\n",
    "else:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# Original path append replaced for Colab compatibility\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from helper_functions import (EmbeddingProvider,\n",
    "                              retrieve_context_per_question,\n",
    "                              replace_t_with_space,\n",
    "                              get_langchain_embedding_provider,\n",
    "                              show_context)\n",
    "\n",
    "from evaluation.evalute_rag import evaluate_rag\n",
    "\n",
    "from langchain.vectorstores import FAISS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVWdzMuw-BE5"
   },
   "source": [
    "### Read Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AagmKvC0-BE6",
    "outputId": "889d0df0-57b3-4e31-a3d5-7ab52ed33892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-06-14 07:31:48--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 206372 (202K) [application/octet-stream]\n",
      "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
      "\n",
      "\r",
      "          data/Unde   0%[                    ]       0  --.-KB/s               \r",
      "data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2025-06-14 07:31:48 (5.89 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
      "\n",
      "--2025-06-14 07:31:48--  https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 206372 (202K) [application/octet-stream]\n",
      "Saving to: ‘data/Understanding_Climate_Change.pdf’\n",
      "\n",
      "data/Understanding_ 100%[===================>] 201.54K  --.-KB/s    in 0.03s   \n",
      "\n",
      "2025-06-14 07:31:48 (5.77 MB/s) - ‘data/Understanding_Climate_Change.pdf’ saved [206372/206372]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download required data files\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Download the PDF document used in this notebook\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n",
    "!wget -O data/Understanding_Climate_Change.pdf https://raw.githubusercontent.com/NirDiamant/RAG_TECHNIQUES/main/data/Understanding_Climate_Change.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KF5O4Wk4-BE6"
   },
   "outputs": [],
   "source": [
    "path = \"data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0MAcEpU-BE6"
   },
   "source": [
    "### Encode document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "38suL-tJ-BE7"
   },
   "outputs": [],
   "source": [
    "def encode_pdf(path, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Encodes a PDF book into a vector store using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        path: The path to the PDF file.\n",
    "        chunk_size: The desired size of each text chunk.\n",
    "        chunk_overlap: The amount of overlap between consecutive chunks.\n",
    "\n",
    "    Returns:\n",
    "        A FAISS vector store containing the encoded book content.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load PDF documents\n",
    "    loader = PyPDFLoader(path)\n",
    "    documents = loader.load()\n",
    "\n",
    "    # Split documents into chunks\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len\n",
    "    )\n",
    "    texts = text_splitter.split_documents(documents)\n",
    "    cleaned_texts = replace_t_with_space(texts)\n",
    "\n",
    "    # Create embeddings (Tested with OpenAI and Amazon Bedrock)\n",
    "    embeddings = get_langchain_embedding_provider(EmbeddingProvider.OPENAI)\n",
    "    #embeddings = get_langchain_embedding_provider(EmbeddingProvider.AMAZON_BEDROCK)\n",
    "\n",
    "    # Create vector store\n",
    "    vectorstore = FAISS.from_documents(cleaned_texts, embeddings)\n",
    "\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8aysEXUh-BE7"
   },
   "outputs": [],
   "source": [
    "chunks_vector_store = encode_pdf(path, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YaCrjGRA-BE7"
   },
   "source": [
    "### Create retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "wgVN3-y1-BE7"
   },
   "outputs": [],
   "source": [
    "chunks_query_retriever = chunks_vector_store.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jQJUmIXS-BE7"
   },
   "source": [
    "### Test retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sC9jmnHM-BE7",
    "outputId": "463219f6-d06c-4031-d348-f89a66ea15c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context 1:\n",
      "Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate. \n",
      "Fossil Fuels \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today. \n",
      "Coal\n",
      "\n",
      "\n",
      "Context 2:\n",
      "Most of these climate changes are attributed to very small variations in Earth's orbit that \n",
      "change the amount of solar energy our planet receives. During the Holocene epoch, which \n",
      "began at the end of the last ice age, human societies flourished, but the industrial era has seen \n",
      "unprecedented changes. \n",
      "Modern Observations \n",
      "Modern scientific observations indicate a rapid increase in global temperatures, sea levels, \n",
      "and extreme weather events. The Intergovernmental Panel on Climate Change (IPCC) has \n",
      "documented these changes extensively. Ice core samples, tree rings, and ocean sediments \n",
      "provide a historical record that scientists use to understand past climate conditions and \n",
      "predict future trends. The evidence overwhelmingly shows that recent changes are primarily \n",
      "driven by human activities, particularly the emission of greenhouse gases. \n",
      "Chapter 2: Causes of Climate Change \n",
      "Greenhouse Gases \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/RAG_TECHNIQUES/helper_functions.py:143: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = chunks_query_retriever.get_relevant_documents(question)\n"
     ]
    }
   ],
   "source": [
    "test_query = \"What is the main cause of climate change?\"\n",
    "context = retrieve_context_per_question(test_query, chunks_query_retriever)\n",
    "show_context(context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbrMQXnX-BE8"
   },
   "source": [
    "### Evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Cjmro4s-BE8",
    "outputId": "45d0a93a-6313-4cdf-a30f-cf7ca9525f0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'questions': ['1. **Multiple Choice: Causes of Climate Change**',\n",
       "  '   - What is the primary cause of the current climate change trend?',\n",
       "  '     A) Solar radiation variations',\n",
       "  '     B) Natural cycles of the Earth',\n",
       "  '     C) Human activities, such as burning fossil fuels',\n",
       "  '     D) Volcanic eruptions',\n",
       "  '',\n",
       "  '2. **True or False: Climate Change Impacts**',\n",
       "  '   - True or False: Climate change only affects the temperature of the planet, not weather patterns, sea levels, or ecosystems.',\n",
       "  '',\n",
       "  '3. **Short Answer: Mitigation Strategies**',\n",
       "  '   - Describe two effective strategies that could be implemented to mitigate the effects of climate change.',\n",
       "  '',\n",
       "  '4. **Matching: Climate Change Terminology**',\n",
       "  '   - Match the following terms with their correct definitions:',\n",
       "  '     A) Greenhouse Gases',\n",
       "  '     B) Carbon Footprint',\n",
       "  '     C) Renewable Energy',\n",
       "  '     D) Adaptation',\n",
       "  '     - Definitions:',\n",
       "  '       1. The total amount of greenhouse gases produced to directly and indirectly support human activities, usually expressed in equivalent tons of carbon dioxide (CO2).',\n",
       "  \"       2. Gases in Earth's atmosphere that trap heat, such as CO2, methane, and nitrous oxide.\",\n",
       "  '       3. Adjusting practices, processes, and capital in response to the risks posed by climate change.',\n",
       "  '       4. Energy from sources that are not depleted when used, such as wind or solar power.',\n",
       "  '',\n",
       "  '5. **Essay: International Cooperation**',\n",
       "  '   - Discuss the importance of international cooperation in combating climate change. Include examples of international agreements or policies that have been implemented to address the issue.'],\n",
       " 'results': ['```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 4,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 5,\\n  \"Conciseness\": 4\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 2,\\n  \"Completeness\": 1,\\n  \"Conciseness\": 2\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 3,\\n  \"Completeness\": 2,\\n  \"Conciseness\": 2\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 4,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 1,\\n  \"Completeness\": 1,\\n  \"Conciseness\": 2\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 1,\\n  \"Completeness\": 1,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 4,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n    \"Relevance\": 5,\\n    \"Completeness\": 5,\\n    \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 1,\\n  \"Completeness\": 1,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n    \"Relevance\": 4,\\n    \"Completeness\": 2,\\n    \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 4,\\n  \"Completeness\": 3,\\n  \"Conciseness\": 2\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 1,\\n  \"Completeness\": 1,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 4,\\n  \"Completeness\": 2,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 3,\\n  \"Completeness\": 2,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 4,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 4,\\n  \"Completeness\": 3,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 4,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 4,\\n  \"Completeness\": 3,\\n  \"Conciseness\": 2\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 1,\\n  \"Completeness\": 1,\\n  \"Conciseness\": 2\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 4,\\n  \"Completeness\": 3,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 5,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 4,\\n  \"Completeness\": 3,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 4,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 1,\\n  \"Completeness\": 1,\\n  \"Conciseness\": 3\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 5,\\n  \"Completeness\": 4,\\n  \"Conciseness\": 4\\n}\\n```',\n",
       "  '```json\\n{\\n  \"Relevance\": 4,\\n  \"Completeness\": 3,\\n  \"Conciseness\": 4\\n}\\n```'],\n",
       " 'average_scores': None}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note - this currently works with OPENAI only\n",
    "evaluate_rag(chunks_query_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "77cFwBpjVMWP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://europe-west1-rag-techniques-views-tracker.cloudfunctions.net/rag-techniques-tracker?notebook=all-rag-techniques--simple-rag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
